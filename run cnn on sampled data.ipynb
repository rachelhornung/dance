{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.log_dir = 'tf_logs/cnn/'+str(time.strftime('%Y-%m%d %H:%M:%S'))\n",
    "config.batch_size = 100\n",
    "config.epochs = 400\n",
    "config.kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "config.pool_size = 2 # we will use 2x2 pooling throughout\n",
    "config.conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "config.conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "\n",
    "config.pool_strides = 2\n",
    "config.conv_strides = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dance.audiosamples import RectifiedAudioSamples as AudioSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"train_data.pkl\")\n",
    "val_data = pd.read_pickle(\"val_data.pkl\")\n",
    "test_data = pd.read_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_samples(train_data, val_data, test_data, sampler):\n",
    "    try:\n",
    "        del(train_samples)\n",
    "        del(val_samples)\n",
    "        del(test_samples)\n",
    "    except:\n",
    "        pass\n",
    "    train_samples = sampler(train_data, subsample_rate=2)\n",
    "    scaler = train_samples.norm()\n",
    "    encoder = train_samples.encode()\n",
    "    val_samples=sampler(val_data, subsample_rate=2)\n",
    "    val_samples.norm(scaler)\n",
    "    val_samples.encode(encoder)\n",
    "    test_samples = sampler(test_data, subsample_rate=2)\n",
    "    test_samples.norm(scaler)\n",
    "    test_samples.encode(encoder)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, val, test = generate_samples(train_data, val_data, test_data, AudioSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Conv1D(config.conv_depth_1, config.kernel_size, input_shape=(train.X.shape[1],1,), activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "model.add(K.layers.MaxPooling1D(config.pool_size, config.pool_strides))\n",
    "# model.add(K.layers.DropOut(config.drop_rate))\n",
    "model.add(K.layers.Conv1D(config.conv_depth_2, config.kernel_size, activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "model.add(K.layers.MaxPooling1D(config.pool_size, config.pool_strides))\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Conv1D(config.conv_depth_2, config.kernel_size, activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "model.add(K.layers.MaxPooling1D(config.pool_size, config.pool_strides))\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.Dense(train.Y.shape[-1], activation='softmax', kernel_regularizer=K.regularizers.l2()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39648 samples, validate on 10166 samples\n",
      "INFO:tensorflow:Summary name conv1d_1/kernel:0 is illegal; using conv1d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_1/bias:0 is illegal; using conv1d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_2/kernel:0 is illegal; using conv1d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_2/bias:0 is illegal; using conv1d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_3/kernel:0 is illegal; using conv1d_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv1d_3/bias:0 is illegal; using conv1d_3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "Epoch 1/400\n",
      "39648/39648 [==============================] - 599s - loss: 3.1333 - acc: 0.2756 - val_loss: 1.9775 - val_acc: 0.2310\n",
      "Epoch 2/400\n",
      "39648/39648 [==============================] - 6037s - loss: 1.8691 - acc: 0.2924 - val_loss: 2.0680 - val_acc: 0.2310\n",
      "Epoch 3/400\n",
      "39648/39648 [==============================] - 427s - loss: 1.8542 - acc: 0.2928 - val_loss: 2.0425 - val_acc: 0.2310\n",
      "Epoch 4/400\n",
      "39648/39648 [==============================] - 411s - loss: 1.8499 - acc: 0.2910 - val_loss: 2.0435 - val_acc: 0.2310\n",
      "Epoch 5/400\n",
      "39648/39648 [==============================] - 426s - loss: 1.8480 - acc: 0.2954 - val_loss: 2.1660 - val_acc: 0.2310\n"
     ]
    }
   ],
   "source": [
    "tbCallback = K.callbacks.TensorBoard(config.log_dir, batch_size=config.batch_size, histogram_freq=10)\n",
    "patience = K.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(train.get_as_timeseries(), train.Y, epochs=config.epochs, \n",
    "                    batch_size=config.batch_size, \n",
    "                    validation_data=(val.get_as_timeseries(), val.Y), \n",
    "                    callbacks=[tbCallback, patience],\n",
    "                    verbose=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18384/18384 [==============================] - 73s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5811073852685142, 0.13163620539599652]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.get_as_timeseries(), y=test.Y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
