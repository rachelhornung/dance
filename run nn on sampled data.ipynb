{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.log_dir = 'tf_logs/nn/'+str(time.strftime('%Y-%m%d %H:%M:%S'))\n",
    "config.batch_size = 400\n",
    "config.epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dance.audiosamples import RectifiedAudioSamples as AudioSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"train_data.pkl\")\n",
    "val_data = pd.read_pickle(\"val_data.pkl\")\n",
    "test_data = pd.read_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_samples(train_data, val_data, test_data, sampler):\n",
    "    try:\n",
    "        del(train_samples)\n",
    "        del(val_samples)\n",
    "        del(test_samples)\n",
    "    except:\n",
    "        pass\n",
    "    train_samples = sampler(train_data, subsample_rate=2)\n",
    "    scaler = train_samples.norm()\n",
    "    encoder = train_samples.encode()\n",
    "    val_samples=sampler(val_data, subsample_rate=2)\n",
    "    val_samples.norm(scaler)\n",
    "    val_samples.encode(encoder)\n",
    "    test_samples = sampler(test_data, subsample_rate=2)\n",
    "    test_samples.norm(scaler)\n",
    "    test_samples.encode(encoder)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_samples(train_data, val_data, test_data, AudioSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Dense(500, activation='softplus', input_dim=train.X.shape[1], kernel_regularizer=K.regularizers.l2()))\n",
    "# model.add(K.layers.Dense(250, activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "model.add(K.layers.Dense(100, activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "# model.add(K.layers.Dense(50, activation='softplus', kernel_regularizer=K.regularizers.l2()))\n",
    "model.add(K.layers.Dense(train.Y.shape[-1], activation='softmax', kernel_regularizer=K.regularizers.l2()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39648 samples, validate on 10166 samples\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/kernel:0 is illegal; using dense_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/bias:0 is illegal; using dense_3/bias_0 instead.\n",
      "Epoch 1/400\n",
      "39648/39648 [==============================] - 18s - loss: 8.2025 - acc: 0.3219 - val_loss: 4.6061 - val_acc: 0.2746\n",
      "Epoch 2/400\n",
      "39648/39648 [==============================] - 15s - loss: 3.1613 - acc: 0.3961 - val_loss: 2.9639 - val_acc: 0.2787\n",
      "Epoch 3/400\n",
      "39648/39648 [==============================] - 15s - loss: 2.4162 - acc: 0.4018 - val_loss: 2.6826 - val_acc: 0.1844\n",
      "Epoch 4/400\n",
      "39648/39648 [==============================] - 15s - loss: 2.1722 - acc: 0.4006 - val_loss: 2.5486 - val_acc: 0.2447\n",
      "Epoch 5/400\n",
      "39648/39648 [==============================] - 15s - loss: 2.0363 - acc: 0.4037 - val_loss: 2.2697 - val_acc: 0.2448\n",
      "Epoch 6/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.9503 - acc: 0.4018 - val_loss: 2.3649 - val_acc: 0.2647\n",
      "Epoch 7/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.8740 - acc: 0.4089 - val_loss: 2.2517 - val_acc: 0.2655\n",
      "Epoch 8/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.8231 - acc: 0.4174 - val_loss: 2.2773 - val_acc: 0.1580\n",
      "Epoch 9/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.7866 - acc: 0.4220 - val_loss: 2.5067 - val_acc: 0.2476\n",
      "Epoch 10/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.7767 - acc: 0.4226 - val_loss: 2.1441 - val_acc: 0.2660\n",
      "Epoch 11/400\n",
      "39648/39648 [==============================] - 18s - loss: 1.7235 - acc: 0.4313 - val_loss: 2.1751 - val_acc: 0.2755\n",
      "Epoch 12/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.7018 - acc: 0.4410 - val_loss: 2.1881 - val_acc: 0.2877\n",
      "Epoch 13/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6922 - acc: 0.4458 - val_loss: 2.1338 - val_acc: 0.2933\n",
      "Epoch 14/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6694 - acc: 0.4531 - val_loss: 2.1303 - val_acc: 0.2542\n",
      "Epoch 15/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6629 - acc: 0.4542 - val_loss: 2.1390 - val_acc: 0.2906\n",
      "Epoch 16/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6648 - acc: 0.4506 - val_loss: 2.1764 - val_acc: 0.2007\n",
      "Epoch 17/400\n",
      "39648/39648 [==============================] - 16s - loss: 1.6374 - acc: 0.4633 - val_loss: 2.1815 - val_acc: 0.2440\n",
      "Epoch 18/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6320 - acc: 0.4675 - val_loss: 2.2224 - val_acc: 0.2769\n",
      "Epoch 19/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6282 - acc: 0.4663 - val_loss: 2.2850 - val_acc: 0.2872\n",
      "Epoch 20/400\n",
      "39648/39648 [==============================] - 15s - loss: 1.6255 - acc: 0.4689 - val_loss: 2.2069 - val_acc: 0.2893\n"
     ]
    }
   ],
   "source": [
    "tbCallback = K.callbacks.TensorBoard(config.log_dir, batch_size=config.batch_size, histogram_freq=10)\n",
    "patience = K.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(train.X, train.Y, epochs=config.epochs, \n",
    "                    batch_size=config.batch_size, \n",
    "                    validation_data=(val.X, val.Y), \n",
    "                    callbacks=[tbCallback, patience],\n",
    "                    verbose=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18240/18384 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3938857830535651, 0.22193211488250653]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.X, y=test.Y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
